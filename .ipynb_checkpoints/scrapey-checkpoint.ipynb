{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "#import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dates = [\\n    '2007-01-01 until:2008-01-01',\\n    '2008-01-01 until:2009-01-01',\\n    '2009-01-01 until:2010-01-01',\\n    '2010-01-01 until:2011-01-01',\\n    '2011-01-01 until:2012-01-01',\\n    '2012-01-01 until:2013-01-01',\\n    '2013-01-01 until:2014-01-01',\\n    '2014-01-01 until:2015-01-01',\\n    '2015-01-01 until:2016-01-01',\\n    '2016-01-01 until:2017-01-01',\\n    '2017-01-01 until:2018-01-01',\\n    '2018-01-01 until:2019-01-01',\\n    '2019-01-01 until:2020-01-01',\\n    '2020-01-01 until:2021-01-01',\\n    '2021-01-01 until:2022-01-01',\\n    '2022-01-01 until:2023-01-01',\\n]\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dates = [\n",
    "    '2007-01-01 until:2008-01-01',\n",
    "    '2008-01-01 until:2009-01-01',\n",
    "    '2009-01-01 until:2010-01-01',\n",
    "    '2010-01-01 until:2011-01-01',\n",
    "    '2011-01-01 until:2012-01-01',\n",
    "    '2012-01-01 until:2013-01-01',\n",
    "    '2013-01-01 until:2014-01-01',\n",
    "    '2014-01-01 until:2015-01-01',\n",
    "    '2015-01-01 until:2016-01-01',\n",
    "    '2016-01-01 until:2017-01-01',\n",
    "    '2017-01-01 until:2018-01-01',\n",
    "    '2018-01-01 until:2019-01-01',\n",
    "    '2019-01-01 until:2020-01-01',\n",
    "    '2020-01-01 until:2021-01-01',\n",
    "    '2021-01-01 until:2022-01-01',\n",
    "    '2022-01-01 until:2023-01-01',\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Creating folders of data for queries, each folder contains csv's titled by date range of when the tweet was tweeted\\n# I did not use a loop here so to query:\\n# -- epidural, natural_birth, natural_labor, unmedicated birth\\n# I reran this cell and edited the appropriate variables, specifically the lines of code:\\n# -- for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'epidural stimulator since:{date}').get_items())\\n# -- df.to_csv(f'epidural_stimulator/{date}.csv')\\n\\n\\ndef scrape_function(date):\\n    attributes_container = []\\n    # Using TwitterSearchScraper to scrape data and append tweets to list\\n    print(f'querying: {date}')\\n    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'epidural stimulator since:{date}').get_items()):\\n        attributes_container.append([tweet.user.username, tweet.date, tweet.likeCount, tweet.sourceLabel, tweet.rawContent])\\n    df = pd.DataFrame(data=attributes_container)\\n    date = date.replace(' ', '')\\n    date = date.replace('-', '_')\\n    df.to_csv(f'epidural_stimulator/{date}.csv')\\n\\n\\n#scrape_function('2007-01-01 until:2008-01-01')\\n\\nlazy_results = []\\nfor parameters in dates:\\n    lazy_result = dask.delayed(scrape_function)(parameters)\\n    lazy_results.append(lazy_result)\\n\\ndask.compute(*lazy_results)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Creating folders of data for queries, each folder contains csv's titled by date range of when the tweet was tweeted\n",
    "# I did not use a loop here so to query:\n",
    "# -- epidural, natural_birth, natural_labor, unmedicated birth\n",
    "# I reran this cell and edited the appropriate variables, specifically the lines of code:\n",
    "# -- for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'epidural stimulator since:{date}').get_items())\n",
    "# -- df.to_csv(f'epidural_stimulator/{date}.csv')\n",
    "\n",
    "\n",
    "def scrape_function(date):\n",
    "    attributes_container = []\n",
    "    # Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "    print(f'querying: {date}')\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'epidural stimulator since:{date}').get_items()):\n",
    "        attributes_container.append([tweet.user.username, tweet.date, tweet.likeCount, tweet.sourceLabel, tweet.rawContent])\n",
    "    df = pd.DataFrame(data=attributes_container)\n",
    "    date = date.replace(' ', '')\n",
    "    date = date.replace('-', '_')\n",
    "    df.to_csv(f'epidural_stimulator/{date}.csv')\n",
    "\n",
    "\n",
    "#scrape_function('2007-01-01 until:2008-01-01')\n",
    "\n",
    "lazy_results = []\n",
    "for parameters in dates:\n",
    "    lazy_result = dask.delayed(scrape_function)(parameters)\n",
    "    lazy_results.append(lazy_result)\n",
    "\n",
    "dask.compute(*lazy_results)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/natural_labor\n",
      "natural_labor\n",
      "data/natural_labor/2009_01_01until:2010_01_01.csv\n",
      "natural_labor\n",
      "data/natural_labor/2013_01_01until:2014_01_01.csv\n",
      "natural_labor\n",
      "data/natural_labor/2015_01_01until:2016_01_01.csv\n",
      "natural_labor\n",
      "data/natural_labor/2010_01_01until:2011_01_01.csv\n",
      "natural_labor\n",
      "data/natural_labor/2022_01_01until:2023_01_01.csv\n",
      "natural_labor\n",
      "data/natural_labor/2019_01_01until:2020_01_01.csv\n",
      "natural_labor\n",
      "data/natural_labor/2020_01_01until:2021_01_01.csv\n",
      "natural_labor\n",
      "data/natural_labor/2011_01_01until:2012_01_01.csv\n",
      "natural_labor\n",
      "data/natural_labor/2021_01_01until:2022_01_01.csv\n",
      "natural_labor\n",
      "data/natural_labor/2014_01_01until:2015_01_01.csv\n",
      "natural_labor\n",
      "data/natural_labor/2016_01_01until:2017_01_01.csv\n",
      "natural_labor\n",
      "data/natural_labor/2017_01_01until:2018_01_01.csv\n",
      "natural_labor\n",
      "data/natural_labor/2008_01_01until:2009_01_01.csv\n",
      "natural_labor\n",
      "data/natural_labor/2012_01_01until:2013_01_01.csv\n",
      "natural_labor\n",
      "data/natural_labor/2007_01_01until:2008_01_01.csv\n",
      "natural_labor\n",
      "data/natural_labor/2018_01_01until:2019_01_01.csv\n",
      "/home/karl/PycharmProjects/epidural/data/natural_labor_combined.csv\n",
      "data/epidural\n",
      "epidural\n",
      "data/epidural/2009_01_01until:2010_01_01.csv\n",
      "epidural\n",
      "data/epidural/2013_01_01until:2014_01_01.csv\n",
      "epidural\n",
      "data/epidural/2015_01_01until:2016_01_01.csv\n",
      "epidural\n",
      "data/epidural/2010_01_01until:2011_01_01.csv\n",
      "epidural\n",
      "data/epidural/2022_01_01until:2023_01_01.csv\n",
      "epidural\n",
      "data/epidural/2019_01_01until:2020_01_01.csv\n",
      "epidural\n",
      "data/epidural/2020_01_01until:2021_01_01.csv\n",
      "epidural\n",
      "data/epidural/2011_01_01until:2012_01_01.csv\n",
      "epidural\n",
      "data/epidural/2021_01_01until:2022_01_01.csv\n",
      "epidural\n",
      "data/epidural/2014_01_01until:2015_01_01.csv\n",
      "epidural\n",
      "data/epidural/2016_01_01until:2017_01_01.csv\n",
      "epidural\n",
      "data/epidural/2017_01_01until:2018_01_01.csv\n",
      "epidural\n",
      "data/epidural/2008_01_01until:2009_01_01.csv\n",
      "epidural\n",
      "data/epidural/2012_01_01until:2013_01_01.csv\n",
      "epidural\n",
      "data/epidural/2007_01_01until:2008_01_01.csv\n",
      "epidural\n",
      "data/epidural/2018_01_01until:2019_01_01.csv\n",
      "/home/karl/PycharmProjects/epidural/data/epidural_combined.csv\n",
      "data/natural_birth\n",
      "natural_birth\n",
      "data/natural_birth/2009_01_01until:2010_01_01.csv\n",
      "natural_birth\n",
      "data/natural_birth/2013_01_01until:2014_01_01.csv\n",
      "natural_birth\n",
      "data/natural_birth/2015_01_01until:2016_01_01.csv\n",
      "natural_birth\n",
      "data/natural_birth/2010_01_01until:2011_01_01.csv\n",
      "natural_birth\n",
      "data/natural_birth/2022_01_01until:2023_01_01.csv\n",
      "natural_birth\n",
      "data/natural_birth/2019_01_01until:2020_01_01.csv\n",
      "natural_birth\n",
      "data/natural_birth/2020_01_01until:2021_01_01.csv\n",
      "natural_birth\n",
      "data/natural_birth/2011_01_01until:2012_01_01.csv\n",
      "natural_birth\n",
      "data/natural_birth/2021_01_01until:2022_01_01.csv\n",
      "natural_birth\n",
      "data/natural_birth/2014_01_01until:2015_01_01.csv\n",
      "natural_birth\n",
      "data/natural_birth/2016_01_01until:2017_01_01.csv\n",
      "natural_birth\n",
      "data/natural_birth/2017_01_01until:2018_01_01.csv\n",
      "natural_birth\n",
      "data/natural_birth/2008_01_01until:2009_01_01.csv\n",
      "natural_birth\n",
      "data/natural_birth/2012_01_01until:2013_01_01.csv\n",
      "natural_birth\n",
      "data/natural_birth/2007_01_01until:2008_01_01.csv\n",
      "natural_birth\n",
      "data/natural_birth/2018_01_01until:2019_01_01.csv\n",
      "/home/karl/PycharmProjects/epidural/data/natural_birth_combined.csv\n",
      "data/unmedicated_birth\n",
      "unmedicated_birth\n",
      "data/unmedicated_birth/2009_01_01until:2010_01_01.csv\n",
      "unmedicated_birth\n",
      "data/unmedicated_birth/2013_01_01until:2014_01_01.csv\n",
      "unmedicated_birth\n",
      "data/unmedicated_birth/2015_01_01until:2016_01_01.csv\n",
      "unmedicated_birth\n",
      "data/unmedicated_birth/2010_01_01until:2011_01_01.csv\n",
      "unmedicated_birth\n",
      "data/unmedicated_birth/2022_01_01until:2023_01_01.csv\n",
      "unmedicated_birth\n",
      "data/unmedicated_birth/2019_01_01until:2020_01_01.csv\n",
      "unmedicated_birth\n",
      "data/unmedicated_birth/2020_01_01until:2021_01_01.csv\n",
      "unmedicated_birth\n",
      "data/unmedicated_birth/2011_01_01until:2012_01_01.csv\n",
      "unmedicated_birth\n",
      "data/unmedicated_birth/2021_01_01until:2022_01_01.csv\n",
      "unmedicated_birth\n",
      "data/unmedicated_birth/2014_01_01until:2015_01_01.csv\n",
      "unmedicated_birth\n",
      "data/unmedicated_birth/2016_01_01until:2017_01_01.csv\n",
      "unmedicated_birth\n",
      "data/unmedicated_birth/2017_01_01until:2018_01_01.csv\n",
      "unmedicated_birth\n",
      "data/unmedicated_birth/2008_01_01until:2009_01_01.csv\n",
      "unmedicated_birth\n",
      "data/unmedicated_birth/2012_01_01until:2013_01_01.csv\n",
      "unmedicated_birth\n",
      "data/unmedicated_birth/2007_01_01until:2008_01_01.csv\n",
      "unmedicated_birth\n",
      "data/unmedicated_birth/2018_01_01until:2019_01_01.csv\n",
      "/home/karl/PycharmProjects/epidural/data/unmedicated_birth_combined.csv\n",
      "data/medication_free_birth\n",
      "medication_free_birth\n",
      "data/medication_free_birth/2009_01_01until:2010_01_01.csv\n",
      "medication_free_birth\n",
      "data/medication_free_birth/2013_01_01until:2014_01_01.csv\n",
      "medication_free_birth\n",
      "data/medication_free_birth/2015_01_01until:2016_01_01.csv\n",
      "medication_free_birth\n",
      "data/medication_free_birth/2010_01_01until:2011_01_01.csv\n",
      "medication_free_birth\n",
      "data/medication_free_birth/2022_01_01until:2023_01_01.csv\n",
      "medication_free_birth\n",
      "data/medication_free_birth/2019_01_01until:2020_01_01.csv\n",
      "medication_free_birth\n",
      "data/medication_free_birth/2020_01_01until:2021_01_01.csv\n",
      "medication_free_birth\n",
      "data/medication_free_birth/2011_01_01until:2012_01_01.csv\n",
      "medication_free_birth\n",
      "data/medication_free_birth/2021_01_01until:2022_01_01.csv\n",
      "medication_free_birth\n",
      "data/medication_free_birth/2014_01_01until:2015_01_01.csv\n",
      "medication_free_birth\n",
      "data/medication_free_birth/2016_01_01until:2017_01_01.csv\n",
      "medication_free_birth\n",
      "data/medication_free_birth/2017_01_01until:2018_01_01.csv\n",
      "medication_free_birth\n",
      "data/medication_free_birth/2008_01_01until:2009_01_01.csv\n",
      "medication_free_birth\n",
      "data/medication_free_birth/2012_01_01until:2013_01_01.csv\n",
      "medication_free_birth\n",
      "data/medication_free_birth/2007_01_01until:2008_01_01.csv\n",
      "medication_free_birth\n",
      "data/medication_free_birth/2018_01_01until:2019_01_01.csv\n",
      "/home/karl/PycharmProjects/epidural/data/medication_free_birth_combined.csv\n"
     ]
    }
   ],
   "source": [
    "directory = 'data/' # must use absolute path\n",
    "directory_list = list(glob.glob(os.path.join(directory,'**')))\n",
    "\n",
    "for dir in directory_list:\n",
    "    print(dir)\n",
    "    dfs = []\n",
    "    for file in os.listdir(dir):\n",
    "        #print(file)\n",
    "        dir_file = dir+'/'+file\n",
    "        name_hold = str(dir[5:])\n",
    "        print(name_hold)\n",
    "        print(dir_file)\n",
    "\n",
    "        data = pd.read_csv(dir_file, lineterminator='\\n')\n",
    "        dfs.append(data)\n",
    "\n",
    "    all_df = pd.concat(dfs, ignore_index=True)\n",
    "    pwd = (str(os.getcwd()))\n",
    "    pwd_dir = pwd+'/'+dir+'_combined.csv'\n",
    "    print(pwd_dir)\n",
    "    all_df.to_csv(pwd_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_620143/109981485.py:1: DtypeWarning: Columns (0,3,4,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  positive_df = pd.read_csv(\"epidural_combined.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.248941e+09</td>\n",
       "      <td>Aztek_King</td>\n",
       "      <td>2009-12-31 21:57:46+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>RT @MissIrisA: Still in labor feeling way bett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.248574e+09</td>\n",
       "      <td>jodyleila</td>\n",
       "      <td>2009-12-31 21:43:45+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>Kourtney Kardashian is quoted as saying \"child...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.248517e+09</td>\n",
       "      <td>ummlayla</td>\n",
       "      <td>2009-12-31 21:41:34+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>@cncz I waited until I was too far into labor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.247907e+09</td>\n",
       "      <td>AureliaCotta</td>\n",
       "      <td>2009-12-31 21:18:52+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>@refashionista Actually that happens regardles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.247751e+09</td>\n",
       "      <td>refashionista</td>\n",
       "      <td>2009-12-31 21:13:06+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>@kateheartfield FWIW, recovery from my unmedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18200330</th>\n",
       "      <td>9.476563e+17</td>\n",
       "      <td>nomina_bot</td>\n",
       "      <td>2018-01-01 02:30:46+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>twittbot.net</td>\n",
       "      <td>硬膜上腔：epidural space #nomina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18200331</th>\n",
       "      <td>9.476407e+17</td>\n",
       "      <td>WrightByrdYT</td>\n",
       "      <td>2018-01-01 01:28:34+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>@Fact Well yeah if you don't have an epidural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18200332</th>\n",
       "      <td>9.476359e+17</td>\n",
       "      <td>MorganShaw513</td>\n",
       "      <td>2018-01-01 01:09:31+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>@lynkrystal Yeah I’m definitely terrified of h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18200333</th>\n",
       "      <td>9.476333e+17</td>\n",
       "      <td>TehAngryAnalyst</td>\n",
       "      <td>2018-01-01 00:59:17+00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>@ThomasKlineMD Managed care was a factor in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18200334</th>\n",
       "      <td>9.476241e+17</td>\n",
       "      <td>c_tittytat</td>\n",
       "      <td>2018-01-01 00:22:54+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>@hcarlin_ I had a 1 degree rip &amp;amp; I kept pu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18200335 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                1                          2    3  \\\n",
       "0         7.248941e+09       Aztek_King  2009-12-31 21:57:46+00:00  0.0   \n",
       "1         7.248574e+09        jodyleila  2009-12-31 21:43:45+00:00  0.0   \n",
       "2         7.248517e+09         ummlayla  2009-12-31 21:41:34+00:00  0.0   \n",
       "3         7.247907e+09     AureliaCotta  2009-12-31 21:18:52+00:00  0.0   \n",
       "4         7.247751e+09    refashionista  2009-12-31 21:13:06+00:00  0.0   \n",
       "...                ...              ...                        ...  ...   \n",
       "18200330  9.476563e+17       nomina_bot  2018-01-01 02:30:46+00:00  0.0   \n",
       "18200331  9.476407e+17     WrightByrdYT  2018-01-01 01:28:34+00:00  0.0   \n",
       "18200332  9.476359e+17    MorganShaw513  2018-01-01 01:09:31+00:00  1.0   \n",
       "18200333  9.476333e+17  TehAngryAnalyst  2018-01-01 00:59:17+00:00  3.0   \n",
       "18200334  9.476241e+17       c_tittytat  2018-01-01 00:22:54+00:00  0.0   \n",
       "\n",
       "                            4  \\\n",
       "0          Twitter Web Client   \n",
       "1          Twitter Web Client   \n",
       "2          Twitter Web Client   \n",
       "3          Twitter Web Client   \n",
       "4          Twitter Web Client   \n",
       "...                       ...   \n",
       "18200330         twittbot.net   \n",
       "18200331  Twitter for Android   \n",
       "18200332   Twitter for iPhone   \n",
       "18200333   Twitter for iPhone   \n",
       "18200334   Twitter for iPhone   \n",
       "\n",
       "                                                          5  \n",
       "0         RT @MissIrisA: Still in labor feeling way bett...  \n",
       "1         Kourtney Kardashian is quoted as saying \"child...  \n",
       "2         @cncz I waited until I was too far into labor ...  \n",
       "3         @refashionista Actually that happens regardles...  \n",
       "4         @kateheartfield FWIW, recovery from my unmedic...  \n",
       "...                                                     ...  \n",
       "18200330                        硬膜上腔：epidural space #nomina  \n",
       "18200331      @Fact Well yeah if you don't have an epidural  \n",
       "18200332  @lynkrystal Yeah I’m definitely terrified of h...  \n",
       "18200333  @ThomasKlineMD Managed care was a factor in th...  \n",
       "18200334  @hcarlin_ I had a 1 degree rip &amp; I kept pu...  \n",
       "\n",
       "[18200335 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df = pd.read_csv(\"epidural_combined.csv\")\n",
    "positive_df.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'],inplace=True)\n",
    "positive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.248941e+09</td>\n",
       "      <td>Aztek_King</td>\n",
       "      <td>2009-12-31 21:57:46+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>RT @MissIrisA: Still in labor feeling way bett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.248574e+09</td>\n",
       "      <td>jodyleila</td>\n",
       "      <td>2009-12-31 21:43:45+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>Kourtney Kardashian is quoted as saying \"child...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.248517e+09</td>\n",
       "      <td>ummlayla</td>\n",
       "      <td>2009-12-31 21:41:34+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>@cncz I waited until I was too far into labor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.247907e+09</td>\n",
       "      <td>AureliaCotta</td>\n",
       "      <td>2009-12-31 21:18:52+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>@refashionista Actually that happens regardles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.247751e+09</td>\n",
       "      <td>refashionista</td>\n",
       "      <td>2009-12-31 21:13:06+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>@kateheartfield FWIW, recovery from my unmedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18200330</th>\n",
       "      <td>9.476563e+17</td>\n",
       "      <td>nomina_bot</td>\n",
       "      <td>2018-01-01 02:30:46+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>twittbot.net</td>\n",
       "      <td>硬膜上腔：epidural space #nomina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18200331</th>\n",
       "      <td>9.476407e+17</td>\n",
       "      <td>WrightByrdYT</td>\n",
       "      <td>2018-01-01 01:28:34+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>@Fact Well yeah if you don't have an epidural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18200332</th>\n",
       "      <td>9.476359e+17</td>\n",
       "      <td>MorganShaw513</td>\n",
       "      <td>2018-01-01 01:09:31+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>@lynkrystal Yeah I’m definitely terrified of h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18200333</th>\n",
       "      <td>9.476333e+17</td>\n",
       "      <td>TehAngryAnalyst</td>\n",
       "      <td>2018-01-01 00:59:17+00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>@ThomasKlineMD Managed care was a factor in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18200334</th>\n",
       "      <td>9.476241e+17</td>\n",
       "      <td>c_tittytat</td>\n",
       "      <td>2018-01-01 00:22:54+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>@hcarlin_ I had a 1 degree rip &amp;amp; I kept pu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18200335 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                1                          2    3  \\\n",
       "0         7.248941e+09       Aztek_King  2009-12-31 21:57:46+00:00  0.0   \n",
       "1         7.248574e+09        jodyleila  2009-12-31 21:43:45+00:00  0.0   \n",
       "2         7.248517e+09         ummlayla  2009-12-31 21:41:34+00:00  0.0   \n",
       "3         7.247907e+09     AureliaCotta  2009-12-31 21:18:52+00:00  0.0   \n",
       "4         7.247751e+09    refashionista  2009-12-31 21:13:06+00:00  0.0   \n",
       "...                ...              ...                        ...  ...   \n",
       "18200330  9.476563e+17       nomina_bot  2018-01-01 02:30:46+00:00  0.0   \n",
       "18200331  9.476407e+17     WrightByrdYT  2018-01-01 01:28:34+00:00  0.0   \n",
       "18200332  9.476359e+17    MorganShaw513  2018-01-01 01:09:31+00:00  1.0   \n",
       "18200333  9.476333e+17  TehAngryAnalyst  2018-01-01 00:59:17+00:00  3.0   \n",
       "18200334  9.476241e+17       c_tittytat  2018-01-01 00:22:54+00:00  0.0   \n",
       "\n",
       "                            4  \\\n",
       "0          Twitter Web Client   \n",
       "1          Twitter Web Client   \n",
       "2          Twitter Web Client   \n",
       "3          Twitter Web Client   \n",
       "4          Twitter Web Client   \n",
       "...                       ...   \n",
       "18200330         twittbot.net   \n",
       "18200331  Twitter for Android   \n",
       "18200332   Twitter for iPhone   \n",
       "18200333   Twitter for iPhone   \n",
       "18200334   Twitter for iPhone   \n",
       "\n",
       "                                                          5  \n",
       "0         RT @MissIrisA: Still in labor feeling way bett...  \n",
       "1         Kourtney Kardashian is quoted as saying \"child...  \n",
       "2         @cncz I waited until I was too far into labor ...  \n",
       "3         @refashionista Actually that happens regardles...  \n",
       "4         @kateheartfield FWIW, recovery from my unmedic...  \n",
       "...                                                     ...  \n",
       "18200330                        硬膜上腔：epidural space #nomina  \n",
       "18200331      @Fact Well yeah if you don't have an epidural  \n",
       "18200332  @lynkrystal Yeah I’m definitely terrified of h...  \n",
       "18200333  @ThomasKlineMD Managed care was a factor in th...  \n",
       "18200334  @hcarlin_ I had a 1 degree rip &amp; I kept pu...  \n",
       "\n",
       "[18200335 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bertopic import BERTopic\n",
    "\n",
    "#model = BERTopic()\n",
    "topics, probabilities = model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
